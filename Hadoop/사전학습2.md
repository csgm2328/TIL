# 사전학습 2

* partitioner Class
  * KEY 대로 같은 reducer로 할당될지 결정을 정의하는 Class
  * 기본 타입은 Hash 함수가 default로 제공중
    * text, intWritable, LongWritable, 등등
* Inverted Index
  * map()의 value를 key의 개수가 아니라 위치(문서번호,줄 위치)로 매핑
  * 그러므로 reduce()는 할일이 없음
  * map()이 인풋데이터의 한줄한줄 실행되는데 key.get()을 하면 그 해당줄이 파일의 몇번째 라인인지 byte offset인지 알 수 있다.
  * mapper 안에 setup() 함수로 파일이름 얻기

* MatrixAdd
  * A + B 행렬을 할때
  * map() 으로 행렬 이름은 버리고 [A x좌표 y좌표 값]으로 들어오는 것을 key는 행열좌표 (x,y) value는 값으로 매핑
  * Shuffle로 같은 key인것들 value list로 정렬
  * reduce()에서 value list 받아서 더함


# 사전학습 3
* MatrixMul
  * key: (i,1),(i,2),,,(i,m)
    * m은 열의 개수
    * A * B: A의 m열 * B의 n행
  * value: (p,행렬 [i,p]의 값)
  <img src="..\assets\hadoop_matmul.JPG">
  * key가 결과의 위치
    * 1-phase 알고리즘
  * key대로 매핑이 되면 reduce에서 value (p, 값)의 p에 맞춰서 계산
  * reduce()를 하기 위해선 valuelist를 다 읽어들인 후 메인 메모리에 넣어야 동작할 수 있는데
  * 하지만 행렬이 너무 크다면 메인메모리에 올릴 수 없는데 그래서 2-phase를 사용
    * 코드
      * main함수에서 configuration 셋팅한거
      * Mapper의 setup()에서 브로드캐스트
      * map()에서 A,B 행렬에 따라 요소를 필요한 만큼 반복해서 키-밸류 생성
      * 행렬 곱은 엇갈려서 A,B 행렬 key-value 엇갈리게 생성
      * 
  * 2-phase 알고리즘
    * key에다가 p도 추가한다
      * ex - key(1,1,1) - value (12)
    * 그러면 shuffle 후에 reduce input으로 각 key당 valuelist가 딱 두개만 떨어진다
    * 두개 곱해서 p 떼고 key로 output하면 첫번째 phase 완료
      <img src="..\assets\hadoop_matmul_2.JPG">
    * 두번째 phase
      * 다시 맵부터 시작
      * key - value가 data로 들어옴 --> key value 구분해서 출력
      * 이번에도 key당 두개의 valuelist를 더해서 최종 출력
      * 1 페이즈에선 value list가 두개 뿐이라 메인메모리 부담없고
      * 2 페이즈에선 행렬이 커져도 단순 더하기는 메인메모리에 부담없다.
      * 메인메모리가 충분히 감당할 수 있다면 map-reduce 작업이 오버헤드가 크므로 1페이즈 알고리즘으로!
      * 