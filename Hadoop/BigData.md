# 빅데이터
* 기존의 컴퓨팅 기술로는 처리할 수 없는 대규모 데이터 세트 모음
  * ex) 구조화된 데이터(관계형), 반구조화(XML), 비정형(Word,pdf,텍스트)
* 이러한 빅데이터를 활용해 광고 효과, 환자 병력과 같은 더 나은 서비스를 위한 의사결정에 사용
* 이를 위해서 정형/비정형 데이트를 실시간으로 관리하고 처리할 인프라 필요 + 보안
* NoSQL은 대규모 계산을 저렴하고 효율적으로 실행하도록 설계됨(MongoDB)
  * MapReduce가 SQL 기능을 보완하고 scale out이 가능하도록 시스템을 제공함.


* 빅데이터 솔루션
  * 수용할 수 없는 막대한 양의 데이터를 처리할 때 병목현상이 발생하는데 이를 해결할 수 있는 솔루션이 MapReduce 알고리즘.
  * MapReduce 알고리즘
    * 작업을 작은 부분으로 나눠 많은 컴퓨터에 할당하고 그 결과 데이터 셋트를 수집한다.
    * 데이터들이 병렬로 처리되어 병목현상 해결
  * Hadoop
    * MapReduce 알고리즘을 사용하여 앱을 실행한다.
    * 고로 여러 MR 알고리즘을 쓸수도 있는 것.
    * 대규모 데이터 세트를 분산처리하는 프레임워크로 말한다.
    * 하둡의 클러스터는 각각 로컬 스토리지와 계산하는 환경을 가진다.
    * 아키텍처
      * 처리/계산 Layer(MR)
      * 스토리지(HDFS)
      <img src="..\assets\hadoop_architecture.JPG">
    * MapReduce
      * 내결함성방식의 병렬 분산 처리 프로그래밍 모델
    * 하둡 분산 파일 시스템(HDFS)
      * 구글 파일 시스템을 기반으로 기존의 분산 파일 시스템과의 차이점은 내결함성이 뛰어나고 저렴한 하드웨어에 배포가능함.
    * Hadoop Common
      * 하둡 모듈에 필요한 JAVA 라이브러리 및 유틸
    * Hadoop YARN
      * 작업 스케줄링 및 클러스터 리소스 관리를 위한 프레임워크
  * 하둡의 작동
    * 컴퓨터 클러스터에서 코드 실행
      * 데이터는 초기에 directory / file로 나뉨
      * 디렉토리는 128MB(혹은 64MB)의 균일한 크기의 블록으로 나뉨
      * 그 후, 추가처리를 위해 클러스터 노드에 배포됨
      * 로컬 파일시스템 위에 있는 HDFS가 처리를 감독
      * 블록 복제
      * 성공 확인
      * 맵과 리듀스 단계 사이 에서 정렬 수행
      * 정렬된 데이터를 특정 컴퓨터로 전송
      * 디버깅 로그
  * 하둡의 장점
    * 데이터와 작업을 머신 전체에 자동 배포
    * 하둡은 FTHA(내결함성 및 고가용성)을 제공하기 위해 하드웨어에 의존하지 않으며, 애플리케이션 계층에서 오류감지와 처리
    * 중단없이 클러스터에서 서버 추가 삭제가능
    * Java 기반, 오픈소스라 모든 플랫폼에서 호환가능
* HDFS
  * 마스터 - 슬레이브 아키텍처
  * 네임 노드
    * 파일시스템 네임스페이스 관리, 파일에 대한 클라이언트 액세스 규제
    * 파일 열기,닫기
  * 데이터 노드
    * 시스템의 데이터 저장소 관리
    * 클라이언트 요청에 따라 읽기쓰기 작업 수행
    * 네임 노드 지시로 생성, 삭제,복제 수행
  * 블록
    * 파일이 저장되는 단위(파일 세그먼트)
    * 읽고 쓰느 최소 데이터 양
    * 기본 64MB
  * 목표
    * 구성된 하드웨어의 빠른 오류 감지 및 복구
    * 수백개의 노드로 빅데이터 세트를 가진 앱 관리
    * 효율적 데이터 처리

* MapReduce
  * Map(변환) + Reduce(결합) 작업
  * Map
    * 데이터 세트를 다른 데이터세트로 변환
    * 요소들은 Tuple(key-value)
  * Reduce
    * Map의 출력을 입력으로 받아 데이터 튜플을 더 작은 튜플 세트로 결합하는 작업
  * 미리 MapReduce로 앱을 작성했다면 앱을 확장하는것은 일도 아니다.
  * 알고리즘
    * Map 단계
      * HDFS에 저장된 입력 데이터를 처리하여 여러 개의 작은 데이터 청크로 생성
    * Reduce 단계
      * Shuffle 단계와의 조합 매퍼에서 가져온 데이터로 새로운 출력 셋트를 생성
    * 하둡은 이 단계를 적절한 서버가 처리하도록 하고 서버에서 처리된 결과는 다시 하둡 서버로 돌아옴
    <img src="..\assets\hadoop_algorithm.JPG">
  * 입출력
    <img src="..\assets\hadoop_io.JPG">
    